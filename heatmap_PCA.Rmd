---
title: "Lenfest model indicators - calculation for EwE models"
author: "Linda Thomas, Camilla Novaglio, Beth Fulton & Javier Porobic"
date: "19/07/2021"
output: html_document
editor_options: 
chunk_output_type: console
---

# Indicator calculation for EwE models
This document provides the scripts to run the Priority 1 indicators for EwE models.
These are calculated using the model output files. Some additional information may be required to be collated.

# Clean up before you start
```{r}
rm(list=ls())
```

# load libraries
Below are the libraries to be loaded - first it runs the function that will check
# if the library is installed or not and if not then installs it so ready for usechecks if installed or not and if not then installs
```{r}
install_load <- function (this_package)  {
    package <- c(this_package)
    if(package %in% rownames(installed.packages()))
        do.call('library', list(package))
    ## if package is not installed locally, download, then load
    else {
        install.packages(package, dependencies=TRUE)
        do.call("library", list(package))
    }
}

### load/install libraries ###
# Data handling and table reshaping
install_load("tidyverse")
install_load("reshape2")
install_load("devtools")
install_load("MASS")
install_load("dplyr")
#install_load("Tool.R")
# Plotting
install_load("ggplot2")
install_load("RColorBrewer")
#install_load("ggbiplot")
install_load("plot3D")
install_load("plotly")
# PCA and Clustering
install_load("factoextra")
install_load("FactoMineR")
install_load("corrplot")
install_load("ape")
install_load("plot3D")
install_load("heatmaply")
install_load("data.table")
# Timeserise analysis
install_load("zoo")
#Other
install_load("Rcpp")
install_load("inline")
install_load("vegan")
install_load("patchwork")
install_load("cowplot")
install_load("ggpubr")
install_load("matrixStats")
install_load("drc")
install_load("viridis")
install_load("gridExtra")
install_load("cowplot")
#Network related
install_load("data.table")
install_load("magrittr")
install_load("qgraph")
install_load("visNetwork")
install_load("intergraph")
install_load("tidygraph")
#install_load("network")
install_load("igraph")
```

# Helpful fucntion for loading EwE files
```{r}
##' @title Skip line function. this automatically get the number of rows based on the ewe version
##' @param file EwE .csv output file
##' @return Number of lines to skip
##' @author Javier Porobic
skip_lines <- function(file){
    strs  <- readLines(file)
    lines <- grep('year\\\\group,', strs) -1
    return(lines)
}
```

# Data collection  
Please set the working directory to where the model output files are.  

Additional information to be provided by the modeller:  
* A list of species used in your model in csv format (e.g ID, Group). This can be taken from the model parameters file used to set up the model.  
* L inf for each species in the model. This is taken from the model parameter file. Calculate the mean L infinity for the species group.
* size categories for each species in csv format (e.g. species_id, Group, size). The information is taken from the model parameters file. Categorise each group into L, S or split depending on total length (small = <30cm, large = >50cm, SPLIT = 30-50cm).

```{r}

# Palettes to use
tscolor <- "red4"
aggtscolor <-"deepskyblue4"
aggtscolor2 <- "deepskyblue"
textsize <- 16
linesize <- 3
nPanel <- 12
use_weights <- 1
chl_from_file <- 0
bo_in_same_file <- 0
bo_conservative <- 1
bo_yr_row <- 0 # Set to 0 if you want the final row of the file
## Area of model in km2 (whole of SESSF = 3700000), EBS smaller
area_model <- 940000

# Define the relevant directories - all these paths (including the output directories) must already exist
mainDir <- "Set_main_directory_here_it_is_directory_above_the_EwE_output_folders"

OutsubDirStep1 <- "Output_of_analysis_folder"
BosubDir <- "Directory_name_for_no_fishing_case"

InputsubDir  <- "Folder_name_of_scenario_to_analyse"

OutsubDirStep2 <- "Where_you_want_to_save_analysis_outputs"

```

# Load the data
```{r}
# set working directory - change to where your model output files are.
setwd(mainDir)
OutsubDirStep3 <- paste(OutsubDirStep1,"/",OutsubDirStep2,sep="")
OutDir <- paste(mainDir,"/",OutsubDirStep3,sep="")
#skip_this  <- header_row_ID - 1

# Create output directory if required
ifelse(!dir.exists(file.path(mainDir, OutsubDirStep1)), dir.create(file.path(mainDir, OutsubDirStep1)), FALSE)
ifelse(!dir.exists(file.path(mainDir, OutsubDirStep3)), dir.create(file.path(mainDir, OutsubDirStep3)), FALSE)
if(!dir.exists(file.path(OutDir))) dir.create(file.path(OutDir))

# read in EwE data
# find model start year from an output file
BioFile <- paste(mainDir,"/",InputsubDir,"/","biomass_annual.csv",sep="")
d <- read.csv(BioFile, header = FALSE)
s_year = d[c(1:7), ];               # this reads the first 7 rows of the header to give the start year of the model.

# catch data
CatchFile <- paste(mainDir,"/",InputsubDir,"/","catch_annual.csv",sep="")
skip_this <- skip_lines(CatchFile)
catch <- read.csv(CatchFile, header = T, skip = skip_this, check.names = FALSE) # because csv file has headers - will need to skip the first 9 rows; check names makes sure an X isn't added before the number for the species
names(catch)[1] <- 'Year'   # changes the name of the first column to year instead of year//group

# aggregate landings data
LandFile <- paste(mainDir,"/",InputsubDir,"/","landings_annual.csv",sep="")
landings <- read.csv(LandFile, header = T, skip = skip_this, check.names = FALSE) # because csv file has headers - will need to skip the first 9 rows; check names makes sure an X isn't added before the number for the species
names(landings)[1] <- 'Year'   # changes the name of the first column to year instead of year//group
names(landings)[3] <- 'species_id'   # changes the name of the first column to year instead of year//group

# biomass data
biomass <- read.csv(BioFile, header = T, skip = skip_this, check.names = FALSE)
names(biomass)[1] <- 'Year'

# total catch and landings data per fleet
RemFile <- paste(mainDir,"/",InputsubDir,"/","catch-fleet-group_annual.csv",sep="")
removals_fleet <- read.csv(RemFile, header = T, skip = skip_this, check.names = FALSE)
names(removals_fleet)[1] <- 'Year'
LFFile <- paste(mainDir,"/",InputsubDir,"/","landings_annual.csv",sep="")
landings_fleet <- read.csv(LFFile, header = T, skip = skip_this, check.names = FALSE)
names(landings_fleet)[1] <- 'Year'

# species id - put names
id <- read.csv("Species_ID.csv") # You will need to put in the name of your species list csv file here
nSPName <- length(unique(id$Group))
SpeciesNames <- id$Group

# fleet id - put names
idf <- read.csv("Fleet_ID.csv") # You will need to put in the name of your species list csv file here
nFName <- length(unique(idf$FleetName))
FleetNames <- idf$FleetName

# mortality data
MortFile <- paste(mainDir,"/",InputsubDir,"/","mort-fleet-group_annual.csv",sep="")
mortality_fleet <- read.csv(MortFile, header = T, skip = skip_this, check.names = FALSE)
names(mortality_fleet)[1] <- 'Year'
MortFile <- paste(mainDir,"/",InputsubDir,"/","mortality_annual.csv",sep="")
mortality <- read.csv(MortFile, header = T, skip = skip_this, check.names = FALSE)
names(mortality)[1] <- 'Year'

# trophic level data
TLFile <- paste(mainDir,"/",InputsubDir,"/","tl_annual.csv",sep="")
tl_annual <- read.csv(TLFile, header = T, skip = skip_this, check.names = FALSE)
names(tl_annual)[1] <- 'Year'   # changes the name of the first column to year instead of year//group

# weight data
WeightFile <- paste(mainDir,"/",InputsubDir,"/","weight_annual.csv",sep="")
weight_annual <- read.csv(WeightFile, header = T, skip = skip_this, check.names = FALSE)
names(weight_annual)[1] <- 'Year'   # changes the name of the first column to year instead of year//group

# chl file if present
if (chl_from_file > 0) {
  ChlFile <- paste(mainDir,"/",InputsubDir,"/","chl.csv",sep="")   # Assumes a format of Year chl
  dfChl <- read.csv(ChlFile, header = T, check.names = FALSE)
  
  # make sure has columns Year and Chl
}

# convert data into a data frame and pivot tables to tidy
bio <- as.data.frame(biomass) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "biomass_tonnes")
bio$biomass_tonnes <- area_model * bio$biomass_tonnes

cat <- as.data.frame(catch) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "catch_tonnes")
cat$catch_tonnes <- area_model * cat$catch_tonnes

aggland <- landings %>%
  group_by(Year, species_id) %>%
  dplyr::summarise(landings_tonnes = sum(value))
aggland$landings_tonnes <- area_model * aggland$landings_tonnes
aggland$species_id <- as.character(aggland$species_id)

tl <- as.data.frame(tl_annual) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "trophic_level")

land <- as.data.frame(landings_fleet) %>% 
  dplyr::rename(species_id = group) %>% # rename group to species_id
  dplyr::rename(fleet_landing_tonnes = value) %>% # rename value to landing_tonnes
  mutate(species_id = as.character(species_id)) %>% 
  unique()
land$fleet_landing_tonnes <- area_model * land$fleet_landing_tonnes

removals <- as.data.frame(removals_fleet) %>% 
  dplyr::rename(species_id = group) %>% # rename group to species_id
  dplyr::rename(fleet_removals_tonnes = value) %>% # rename value to landing_tonnes
  mutate(species_id = as.character(species_id)) %>% 
  unique()
removals$fleet_removals_tonnes <- area_model * removals$fleet_removals_tonnes

# add in species names to the data frame
## change the COL_ID to species_id so can join
id2 <- id %>% 
  dplyr::rename(species_id = ID) %>%  # specify that the dplyr rename is the function you want & rename ID to species_id
#    select(-COL_ID) %>% # removes the COL_ID column
  mutate(species_id = as.character(species_id)) %>% # change to character so same as other data frame
  unique() # make sure only unique values are used.

# merge the catch and biomass into one data frame
df1tmp <- full_join(bio, cat) # have two columns the same so they will automatically join on these
df1 <- full_join(df1tmp, aggland)
df1[is.na(df1)] <- 0
df <- full_join(df1, id2) # data frame with biomass, catch and species names

# df3 <- full_join(df, land) %>% # data frame with biomass, catch and species names & landings
#  select(Year, species_id, Group, fleet, biomass_tonnes, catch_tonnes, fleet_landing_tonnes) # reorder the columns so they are easier to read

# New df3 which has landings and total catch per fleet in one file
df3tmp <- full_join(land, removals)

# Join landings and species names
df3tmpA <- full_join(df3tmp, id2) 
df3 <- merge(df3tmpA, idf, by.x = "fleet", by.y = "ID") 

# add species names to trophic level data
tl_species <- full_join(tl, id2)

# Get reference values
# Depending on the value of bo_conservative set Bo
# bo_in_same_file = 1 then take Bs from row bo_yr_row
# bo_in_same_file = 0 and bo_conservative = 0 then take Bs from the Bo file as dicatted by bo_yr_row
# bo_in_same_file = 0 and bo_conservative = 1 then take max(first row of biofile, row of Bo file)

if(bo_in_same_file < 1){
  # Load Bo and Mo from files
  #bo_skip_this <- bo_header_row_ID - 1
  BoBioFile <- paste(mainDir,"/",BosubDir,"/","biomass_annual.csv",sep="")
  bo_skip_this <- skip_lines(BoBioFile)
  BoBio <- read.csv(BoBioFile, header = T, skip = bo_skip_this, check.names = FALSE)
  MoMortFile <- paste(mainDir,"/",BosubDir,"/","mortality_annual.csv",sep="")
  MoMort <- read.csv(MoMortFile, header = T, skip = bo_skip_this, check.names = FALSE)
  names(BoBio)[1] <- 'Year'
  names(MoMort)[1] <- 'Year' 
  if(bo_yr_row < 1) {
    bo_yr_row <- length(BoBio[,1])
    RefB <- BoBio[bo_yr_row,]
    RefM <- MoMort[bo_yr_row,]
    
  } else {
    RefB <- BoBio[bo_yr_row,]
    RefM <- MoMort[bo_yr_row,]
  }
  
  if(bo_conservative > 0) {
    altB1 <- as.data.frame(RefB) %>% 
      pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
    altBtmp <- biomass[1,]
    altB2 <- as.data.frame(altBtmp) %>% 
      pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
    altB1$Year <- RefM[1,1]
    altB2$Year <- RefM[1,1]
    dftmp <- merge(altB1, altB2, by=c("Year","species_id"))
    dftmp$RefB <- ifelse(dftmp$RefB.x > dftmp$RefB.y, dftmp$RefB.x, dftmp$RefB.y)
    dfRefB <- dftmp
    dfRefB <- subset (dfRefB, select = -c(Year, RefB.x, RefB.y))
  } else {
    dfRefB <- as.data.frame(RefB) %>% 
      pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
    dfRefB <- subset (dfRefB, select = -c(Year))
  }
  dfRefM <- as.data.frame(RefM) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "RefM")
  dfRefM <- subset (dfRefM, select = -c(Year))
  
} else {
  # Assumes has sensible reference year rown number
  RefB <- biomass[bo_yr_row,]
  RefM <- mortality[bo_yr_row,]
  
  dfRefB <- as.data.frame(RefB) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
  dfRefB <- subset (dfRefB, select = -c(Year))
  dfRefM <- as.data.frame(RefM) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "RefM")
  dfRefM <- subset (dfRefM, select = -c(Year))

}
dfRef <- merge(dfRefM, dfRefB, by=c("species_id")) # Intentional reuse
dfRef$RefBo <- area_model * dfRef$RefB

```

## Catch species composition - fishery
PCA run on the output file (catch_fleet_group_annual)
```{r}

#Create a clean version of SP_as_col
CdataS <- df

# Replace spaces in names with "_"
CdataS$Group <- gsub("\\(", "", CdataS$Group)
CdataS$Group <- gsub("\\/", "", CdataS$Group)
CdataS$Group <- gsub(")", "", CdataS$Group)
CdataS$Group <- gsub("&", "", CdataS$Group)
CdataS$Group <- gsub("-", "", CdataS$Group)
CdataS$Group <- gsub(" ", "", CdataS$Group)
#CdataS$Group <- gsub("  ", " ", CdataS$Group)
#CdataS$Group <- gsub(" ", "_", CdataS$Group)
#SP_as_colA <- reshape2::dcast(CdataS, Year ~ Group, value.var = "TotalYield")

SP_as_colA <- reshape2::dcast(CdataS, Year ~ Group, value.var = "catch_tonnes")

# Replace NA with zeros
SP_as_colA[is.na(SP_as_colA)] <- 0

# Strip out columns of all zeros
SP_as_col <- SP_as_colA[, colSums(SP_as_colA != 0) > 0]

# Get the column headers
dimC <- dim(SP_as_col)
pc.f <- formula(paste("~", paste(names(SP_as_col)[2:dimC[2]], collapse = "+")))

# PCA calculations - using spectral decomposition approach via the princomp approach
pl.pca <- princomp(pc.f, cor=TRUE, data=SP_as_col)

# Put on row named
row.names(pl.pca$scores) <- SP_as_col$Year

# Plot results - look to see number of PCA axes to retain
OutFilename <- paste(OutDir,"/PCA_VarExplained.png",sep="")
png(OutFilename, 1200, 800)
plot(pl.pca, type="lines")
dev.off()
  
# Plot biplot
outBiplot <- paste(OutDir,"/PCA_Biplot_Thru_Time.png",sep="")   
dfPCA <- data.frame(comp1=pl.pca$scores[,1],
                 comp2=pl.pca$scores[,2])
ggplot(data = dfPCA, aes(x=comp1, y=comp2, group=1)) +
    geom_point(size=5, aes(colour=rownames(pl.pca$scores))) +
    geom_path(size = 0.2) +
    geom_text(label=rownames(pl.pca$scores)) + 
    theme(legend.position="none")
ggsave(file=outBiplot)

## Use prcomp() instead - this uses singular value decomposition (can handle case when there is more variables than observations)
res.pca <- prcomp(SP_as_col, scale = TRUE)

# Visualize eigenvalues (scree plot). Show the percentage of variances explained by each principal component.
OutFilename <- paste(OutDir,"/PCA_Scree_plot.png",sep="")
png(OutFilename, 1200, 800)
fviz_eig(res.pca)
dev.off()

#Graph of individuals. Individuals with a similar profile are grouped together.
fviz_pca_ind(res.pca,
             col.ind = "contrib", # Color by congtribution
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             #label=SP_as_col$Year
) +
  labs(title ="PCA", x = "PC1", y = "PC2")

# Graph of variables
PCA_color_gradient <- c("#36648B", "#FFA500", "#8B2500")
PCA_color_gradient <- brewer.pal(9, name="YlOrBr")[c(3,4,5,6,7,8,9)]

OutFilename <- paste(OutDir,"/Biplot_attribution.png",sep="")
png(OutFilename, 1200, 800)
fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = PCA_color_gradient,
             repel = TRUE     # Avoid text overlapping
)
dev.off()

# Compute hierarchical clustering on principal components
res.pca4 <- PCA(SP_as_col, ncp = 3, graph = FALSE)
res.hcpc <- HCPC(res.pca4, graph = FALSE)

OutFilename <- paste(OutDir,"/PCA_score_dendrogram.png",sep="")
png(OutFilename, 1200, 800)
fviz_dend(res.hcpc, 
          cex = 0.7,                     # Label size
          palette = "jco",               # Color palette see ?ggpubr::ggpar
          rect = TRUE, rect_fill = TRUE, # Add rectangle around groups
          rect_border = "jco",           # Rectangle color
          labels_track_height = 0.8      # Augment the room for labels
)
dev.off()

OutFilename <- paste(OutDir,"/PCA_score_clusters.png",sep="")
png(OutFilename, 1200, 800)
fviz_cluster(res.hcpc,
             repel = TRUE,            # Avoid label overlapping
             show.clust.cent = TRUE, # Show cluster centers
             palette = "jco",         # Color palette see ?ggpubr::ggpar
             ggtheme = theme_bw(),
             main = "Factor map"
)
dev.off()

```

# Heatmaps - do last as messes up the plotting functions
```{r}
# Create a clean version of SP_as_col
CdataS <- df

# Replace spaces in names with "_"
CdataS$Group <- gsub("\\(", "", CdataS$Group)
CdataS$Group <- gsub("\\/", "", CdataS$Group)
CdataS$Group <- gsub(")", "", CdataS$Group)
CdataS$Group <- gsub("&", "", CdataS$Group)
CdataS$Group <- gsub("-", "", CdataS$Group)
CdataS$Group <- gsub(" ", "", CdataS$Group)
SP_as_colA <- reshape2::dcast(CdataS, Year ~ Group, value.var = "landings_tonnes")

# Replace NA with zeros
SP_as_colA[is.na(SP_as_colA)] <- 0

# Strip out columns of all zeros
SP_as_col <- SP_as_colA[, colSums(SP_as_colA != 0) > 0]

# Create row names and trim off first column
rownames(SP_as_col) <- SP_as_col[,1]
SP_as_col <- SP_as_col %>% dplyr::select(-Year)

# Transpose SP_as_col so years are column headers
# Here the va;ues are proportion of the catch but could be absolute catch
Yr_as_col <- t(SP_as_col)

#Replace NA with 0
Yr_as_col[is.na(Yr_as_col)] <- 0
Prop_Catch <- apply(Yr_as_col, 2, function(i) i/sum(i))

nSP <- length(Yr_as_col[,1])
nYr <- length(Yr_as_col[1,])

# Create new df to populate
drRanked <- data.frame(matrix(ncol = nYr, nrow = nSP))
colnames(drRanked)[1:nYr] = as.character(colnames(Yr_as_col)[1:nYr])
rownames(drRanked)[1:nSP] = as.character(rownames(Yr_as_col)[1:nSP])

# Do ranking (using order() routine as want largest value to be rated 1)
for (i in 1:nSP) {
  drRanked[i,] <- frank(Yr_as_col[i,], ties.method ="dense")
}

# Create the heatmap
HeatmapFilename <- paste("Landings heatmap.pdf",sep="") 
HeatmapTitle <- paste("Catch composition heatmap - catch data",sep="") 

# Create the heatmap - switch our row for both to see if years cluster up
heatmaply(drRanked,
          xlab = "Year",
          ylab = "Species",
          main = HeatmapTitle,
          dendrogram = "row",
          #dendrogram = "both",
          fontsize_col = 6,
          fontsize_row = 8,
          file = HeatmapFilename
)

HeatmapFilename <- paste("Proportion of landings heatmap.pdf",sep="") 
HeatmapTitle <- paste("Catch composition heatmap - proportion of catchh",sep="") 
heatmaply(Prop_Catch,
          xlab = "Year",
          ylab = "Species",
          main = HeatmapTitle,
          dendrogram = "row",
          fontsize_col = 6,
          fontsize_row = 8,
          file = HeatmapFilename
)
```